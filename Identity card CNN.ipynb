{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:02:20.360627Z",
     "start_time": "2020-04-30T10:02:19.666138Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{max-width:90%!important;width:auto!important;}</style>\"))\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize and rotate images if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "import pdb\n",
    "import cv2\n",
    "import requests\n",
    "import mimetypes\n",
    "import json\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "def show_img(im, ax=None, figsize=(8,8), title=None):\n",
    "    if not ax: _,ax = plt.subplots(1,1,figsize=figsize)\n",
    "    if len(im.shape)==2: im = np.tile(im[:,:,None], 3) \n",
    "    ax.imshow(im);\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    if title: ax.set_title(title)\n",
    "    return ax\n",
    "#End of show_img\n",
    "\n",
    "def rotate_bound(image, angle):\n",
    "    # Rotate images\n",
    "    # Example from PYImageSearch, by Adrian Rosebrock\n",
    "    # grab the dimensions of the image then determine the center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "\n",
    "    # grab rotation matrix (applying the negative of the angle to rotate clockwise), \n",
    "    # then grab sine and cosine (i.e. rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    # compute new bounding dimensions of image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "    # adjust rotation matrix to take translation into account \n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "    # perform rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))\n",
    "#End of rotate_bound\n",
    "    \n",
    "\n",
    "class CardTrainData():\n",
    "    \n",
    "\n",
    "    GOOD = \"Id\\\\\"\n",
    "    BAD =   \"Notid\\\\\"\n",
    "    LABELS = {GOOD: 1, BAD: 0}\n",
    "    training_data = []\n",
    "    TrainingGoodIdcount = 0\n",
    "    TrainingBadIdcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        print('Starting to process Training Data')\n",
    "        for label in self.LABELS:\n",
    "                    \n",
    "            folder = (Jobpath+label)           \n",
    "            for f in tqdm(os.listdir(folder)):  \n",
    "                if 'jpeg'or 'jpg' in f:      \n",
    "                    try:\n",
    "                        path = os.path.join(folder, f)\n",
    "                        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        # print('Source image location is:  ',path)  #for checking - comment out or remove\n",
    "                        \n",
    "                        (h, w) = img_data.shape[:2]\n",
    "                        if h > w:\n",
    "                           img_data = rotate_bound(img_data, -90) \n",
    "                        \n",
    "                        img_data = cv2.resize(img_data, Size ) #was self.Size\n",
    "                        #img_data = img_data[:, :, [2, 1, 0]] #needed t\n",
    "                        \n",
    "                        self.training_data.append([(np.array(img_data))/255, np.eye(2)[self.LABELS[label]]])  \n",
    "                        #print('Label is :-  ',np.eye(2)[self.LABELS[label]], self.LABELS[label]) #for checking - comment out or remove\n",
    "                        \n",
    "                        if [self.LABELS[label]] == [1]:\n",
    "                            self.TrainingGoodIdcount += 1\n",
    "                        elif [self.LABELS[label]] == [0]:\n",
    "                            self.TrainingBadIdcount += 1\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "        show_img(img_data,figsize=(8,8)) # Just as a check when testing program\n",
    "        np.random.shuffle(self.training_data)  \n",
    "        ##self.training_data = []\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "       \n",
    "# End of class CardTrainData()\n",
    "\n",
    "\n",
    "class CardTestData():\n",
    "    \n",
    "    GOOD = \"Idtest\\\\\"\n",
    "    BAD = \"Notidtest\\\\\"\n",
    "    LABELS = {GOOD: 1, BAD: 0}\n",
    "    test_data = []\n",
    "    TestGoodIdcount = 0\n",
    "    TestBadIdcount = 0\n",
    "    \n",
    "    def make_test_data(self):\n",
    "        print('Starting to process Test Data')\n",
    "        for label in self.LABELS:\n",
    "                    \n",
    "            folder = (Jobpath+label)           \n",
    "            for f in tqdm(os.listdir(folder)):  \n",
    "                if \"jpeg\" or \"jpg\" in f:      \n",
    "                    try:\n",
    "                        path = os.path.join(folder, f)\n",
    "                        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        # print('Source image location is:  ',path)  #for checking - comment out or remove\n",
    "                        \n",
    "                        (h, w) = img_data.shape[:2]\n",
    "                        if h > w:\n",
    "                           img_data = rotate_bound(img_data, -90) \n",
    "                        \n",
    "                        img_data = cv2.resize(img_data, Size )\n",
    "                        #img_data = img_data[:, :, [2, 1, 0]] #needed to correct colour change if in RGB\n",
    "                        \n",
    "                        self.test_data.append([(np.array(img_data))/255, np.eye(2)[self.LABELS[label]]])  \n",
    "                       #print('Label is :-  ',np.eye(2)[self.LABELS[label]], self.LABELS[label]) #for checking - comment out or remove\n",
    "                        \n",
    "                        if [self.LABELS[label]] == [1]:\n",
    "                            self.TestGoodIdcount += 1\n",
    "                        elif [self.LABELS[label]] == [0]:\n",
    "                            self.TestBadIdcount += 1\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                    \n",
    "        show_img(img_data,figsize=(8,8)) # Just as a check when testing programs            \n",
    "        #show_img(self.test_data[0],figsize=(8,8)) # Just as a check when testing programs\n",
    "        np.random.shuffle(self.test_data)        \n",
    "        np.save(\"test_data.npy\", self.test_data)\n",
    "       \n",
    "# End of class CardTestData()\n",
    "\n",
    "Jobpath = \"C:\\\\Users\\\\aer8\\\\Downloads\\\\L7cv\\\\\"\n",
    "\n",
    "\n",
    "DoTrainingDataOnly = True # Set to False for Test Data only\n",
    "\n",
    "Size =   128, 80   #512, 320     #  # 256,160\n",
    "\n",
    "if DoTrainingDataOnly:\n",
    "    print('**********   Training Data')\n",
    "   \n",
    "    \n",
    "    datatestproc = CardTrainData()\n",
    "    datatestproc.make_training_data()\n",
    "\n",
    "    print('GoodIds:',datatestproc.TrainingGoodIdcount)  #for checking - comment out or remove\n",
    "    print('BadIds: ',datatestproc.TrainingBadIdcount)   #for checking - comment out or remove    \n",
    "    print('A variable called training_data has been generated and a file called training_data.npy has been saved')   \n",
    "        \n",
    "    #print(CardData.Count )\n",
    "\n",
    "    print(CardTrainData.training_data[1]) # prints first image data and its label\n",
    "    #show_img(CardTrainData.training_data[1], figsize=(8,8)) \n",
    "    print()\n",
    "\n",
    "#else:\n",
    "\n",
    "    print('**********   Test Data'    )\n",
    "\n",
    "    datatestproc = CardTestData()\n",
    "    datatestproc.make_test_data()\n",
    "\n",
    "    print('GoodIds:',datatestproc.TestGoodIdcount)  #for checking - comment out or remove\n",
    "    print('BadIds: ',datatestproc.TestBadIdcount)   #for checking - comment out or remove    \n",
    "    print('A variable called test_data has been generated and a file called test_data.npy has been saved')\n",
    "\n",
    "    print(CardTestData.test_data[1]) # prints first image data and its label\n",
    "    #show_img(CardTrainData.training_data[1], figsize=(8,8)) \n",
    "    print()\n",
    " \n",
    "print('Data prepared')\n",
    "\n",
    "xtraindata = np.load(\"training_data.npy\", allow_pickle=True)# For test only\n",
    "xtestdata = np.load(\"test_data.npy\",allow_pickle=True )     # For test only \n",
    "\n",
    "print(xtraindata[5]) # prints one example of image data and its label for testing\n",
    "print(xtestdata[5]) # prints one example of image data and its label for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "\n",
    "        x = torch.randn(128,80).view(-1,1,128,80)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 128) #flattening.\n",
    "        self.fc2 = nn.Linear(128, 2) #    128 in, 2 out bc we're doing 2 classes (id or not).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print ('started')\n",
    "device = torch.device (\"cpu\") # PyTorch v0.4.0\n",
    "model = Net().to(device)\n",
    "summary(model, (1, 128,80))\n",
    "print(net)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "#loss_function = nn.SmoothL1Loss()\n",
    "#loss_function = nn.L1Loss()\n",
    "#loss_function = nn.HingeEmbeddingLoss()\n",
    "#loss_function = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = torch.Tensor([i[0] for i in CardTrainData.training_data]).view(-1,128,80)\n",
    "\n",
    "#y = torch.Tensor([i[1] for i in CardTrainData.training_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtraindata = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "\n",
    "train_X = torch.Tensor([i[0] for i in xtraindata]).view(-1,256,160)\n",
    "\n",
    "train_y = torch.Tensor([i[1] for i in xtraindata])\n",
    "\n",
    "#VAL_PCT = 0.5  # lets do 50% to save time during program testing\n",
    "#val_size = int(len(X)*VAL_PCT)\n",
    "#val_size = len(X)\n",
    "#print(val_size)\n",
    "\n",
    "#train_X = X[:-val_size]\n",
    "#train_y = y[:-val_size]\n",
    "\n",
    "print(len(train_X))\n",
    "\n",
    "#test_X = X[-val_size:]\n",
    "#test_y = y[-val_size:]\n",
    "#print(len(train_X), len(test_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 #reduce from 100 to 10 for testing\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 256,160)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "    print(f\"Epoch: {epoch}. loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T10:02:24.731625Z",
     "start_time": "2020-04-30T10:02:24.577088Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_epoch(net, loss, dl, opt=None, metric=None):\n",
    "    \n",
    "    if opt:\n",
    "        net.train()  # only affects some layers\n",
    "    else:\n",
    "        net.eval()\n",
    "        rq_stored = []\n",
    "        for p in net.parameters():\n",
    "            rq_stored.append(p.requires_grad)\n",
    "            p.requires_grad = False\n",
    "    \n",
    "    L, M = [], []\n",
    "    dl_it = iter(dl)\n",
    "    for xb, yb in tqdm(dl_it, leave=False):\n",
    "        xb, yb = xb, yb\n",
    "        y_ = net(xb)\n",
    "        l = loss(y_, yb)\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "        L.append(l.detach().cpu().numpy())\n",
    "        if metric: M.append(metric(y_, yb).cpu().numpy())\n",
    "        \n",
    "    if not opt:\n",
    "        for p,rq in zip(net.parameters(), rq_stored): p.requires_grad = rq\n",
    "            \n",
    "    return L, M    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X = torch.Tensor([i[0] for i in CardTestData.test_data]).view(-1,256,160)\n",
    "\n",
    "#y = torch.Tensor([i[1] for i in CardTestData.test_data])\n",
    "\n",
    "xtestdata = np.load(\"test_data.npy\",allow_pickle=True )\n",
    "\n",
    "test_X = torch.Tensor([i[0] for i in xtestdata]).view(-1,256,160)\n",
    "\n",
    "test_y = torch.Tensor([i[1] for i in xtestdata])\n",
    "\n",
    "TP = 0 #True positive count \n",
    "FP = 0 #False positive count\n",
    "FN = 0 #False negative count\n",
    "TN = 0 #True negative count\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 256,160))[0]  # returns a list, \n",
    "        predicted_class = torch.argmax(net_out)\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1          \n",
    "        total += 1\n",
    "        \n",
    "        if predicted_class == real_class:\n",
    "            if real_class == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:           \n",
    "            if real_class == 1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "         \n",
    "\n",
    "print('Accuracy: %.3f' % (round(correct/total, 3)))       \n",
    "#print(\"Accuracy: \", round(correct/total, 3))\n",
    "print()\n",
    "print('Extra for Confusion Matrix')\n",
    "print('Sensitivity: %.3f' % (round(TP/(TP+FN), 3)))   \n",
    "print('Precision: %.3f' % (round(TP/(TP+FP), 3)))   \n",
    "print('Accuracy: %.3f' % (round((TP + TN)/(TP+TN+FP+FN), 3)))  \n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "704px",
    "left": "137px",
    "top": "110.444px",
    "width": "180.903px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "160"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
